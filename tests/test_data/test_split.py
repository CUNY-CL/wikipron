import collections
import json
import pytest
import os

from typing import Set

from data.scrape.lib.languages_update import _detect_best_script_name
from data.scrape.lib.split import _generalized_check

_REPO_DIR = os.path.dirname(
    os.path.dirname(os.path.dirname(os.path.realpath(__file__)))
)
_LANGUAGES = os.path.join(_REPO_DIR, "data/scrape/lib/languages.json")

SmokeTestScript = collections.namedtuple(
    "SmokeTestScript", ("script", "samples")
)
SmokeTestScript.__doc__ = """
A script and a list of orthographic samples to run
a smoke test on.

Parameters
----------
script : str
    Unicode script name.
samples : list
    List of tuples containing samples of various scripts
    and a boolean reflecting whether those samples are
    within that Unicode script range.
"""

_SMOKE_TEST_LANGUAGES = [
    SmokeTestScript(
        "Han",
        [
            ("ç€¨å°¿è¦", True),
            ("Mandarin", False),
            ("à¸à¸‡à¸ªà¸¸à¸¥", False),
            ("çƒˆæ—¥xç©º", False),
            ("ãŸæ—¥ç•¶ç©º", False),
        ],
    ),
    SmokeTestScript(
        "Hiragana",
        [
            ("ã‚ã„ãã©ã†", True),
            ("Lucas", False),
            ("ã‚·ãƒŸãƒ¼ã‚º", False),
            ("ã‚ã„ã‹ã‚¤ã‚‰ãš", False),
        ],
    ),
    SmokeTestScript(
        "Hebrew",
        [
            ("×¢×œ×™×ª×", True),
            ("Ğ¼ĞµÑ›Ğ°Ğ²Ğ°", False),
            ("×¢×œb×ª×", False),
            ("Ï€×™×ª×", False),
        ],
    ),
    SmokeTestScript(
        "Syriac", [("ÜÜ’ÜÜ•Ü˜Ü¬Ü", True), ("ÜÜ’ÜÜ•×Ü¬Ü", False), ("cÜ˜Ü˜l", False)]
    ),
    SmokeTestScript("Balinese", [("á¬°á¬¶á¬®á¬µ", True), ("á¬°Ğ½á¬®á¬°à¸ªà¸¸á¬®á¬µ", False)]),
    SmokeTestScript("Tagalog", [("áœ‹áœ‡áœ‡áœŒ", True), ("áœ‹áœ‡áœ‡báœŒ", False)]),
    SmokeTestScript("Cyrillic", [("Ğ½Ğ°Ğ¸Ğ¼Ğµ", True), ("Ğ½Ğ°Ğ¸mĞµ", False)]),
    SmokeTestScript(
        "Bengali",
        [
            ("à¦¬à§à¦°à¦¾à¦¹à§à¦®à§€à¦•à§‡", True),
            ("à¦…à¦¸à¦®à§€à¦¯à¦¼à¦¾", True),  # Assamese.
            ("à¤¦à¤°à¥â€à¤¯à¤¾", False),
        ],
    ),
    SmokeTestScript("Devanagari", [("à¤¬à¥à¤°à¤¾à¤¹à¥à¤®à¤¿à¤•", True), ("à¸ à¹„à¸à¹ˆ", False)]),
    SmokeTestScript("Gujarati", [("àª¬à«àª°àª¾àª¹à«àª®à«€àª•", True), ("à¤¬à¥à¤°à¤¾à¤¹à¥à¤®à¤¿à¤•", False)]),
    SmokeTestScript(
        "Gurmukhi", [("à¨²à©‚à©°à¨¬à©œà©€", True), ("à©", True), ("à¨²à¨¬à¸¥à©œà©€", False)]
    ),
    SmokeTestScript("Kannada", [("à²¬à³à²°à²¾à²¹à³à²®à²¿à²•à³", True), ("â°–", False)]),
    SmokeTestScript("Malayalam", [("à´¬àµà´°à´¾à´¹àµà´®à´¿à´•àµ", True), ("â°–", False)]),
    SmokeTestScript("Oriya", [("à¬¬à­à¬°à¬¾à¬¹à­à¬®à­€à¬¸à¬¿", True), ("â°–", False)]),
    SmokeTestScript("Sinhala", [("à¶¶à·Šà¶»à·à·„à·Šà¶¸à·’à¶šà·Š", True), ("â°–", False)]),
    SmokeTestScript("Tamil", [("à®ªà®¿à®°à®¾à®®à®¿à®•à¯", True), ("â°–", False)]),
    SmokeTestScript("Telugu", [("à°¬à±à°°à°¹à±à°®à°¿à°•à°¿", True), ("â°–", False)]),
    SmokeTestScript(
        "Katakana", [("ã‚·ãƒ‹ãƒ¨ãƒ³", True), ("ã‚ã„ã", False), ("ç€¨", False)]
    ),
    SmokeTestScript("Imperial Aramaic", [("ğ¡€ğ¡…ğ¡“ğ¡”ğ¡‹ğ¡Œ", True), ("ğ¡€Ü’ğ¡“ğ¡”ğ¡‹ğ¡Œ", False)]),
    SmokeTestScript(
        "Latin", [("wikipron", True), ("Ğ°Ğµ", False), ("lá»‹ch", True)]
    ),
    SmokeTestScript("Arabic", [("Ú˜Û‡Ø±Ù†Ø§Ù„", True), ("Ú˜×œØ±Ù†Ø§Ù„", False)]),
    SmokeTestScript(
        "Lao", [("àºàº±àºšàº„àº·àº™", True), ("Ú˜×œØ±Ù†Ø§Ù„", False), ("wikipron", False)]
    ),
    SmokeTestScript(
        "Gothic", [("ğŒ°ğŒ²ğŒ²ğŒ¹ğŒ»ğŒ¿ğƒ", True), ("Ú˜×œØ±Ù†Ø§Ù„", False), ("wikipron", False)]
    ),
    SmokeTestScript(
        "Inherited", [("Ù”", True), ("Ú˜×œØ±Ù†Ø§Ù„", False), ("wikipron", False)]
    ),
    SmokeTestScript(
        "Tai Tham", [("á¨¾á©®á©¥á© á¨¦", True), ("Ú˜×œØ±Ù†Ø§Ù„", False), ("wikipron", False)]
    ),
    SmokeTestScript(
        "Old Italic",
        [("ğŒƒğŒ–ğŒ„ğŒğŒğŒ”", True), ("Ú˜×œØ±Ù†Ø§Ù„", False), ("wikipron", False)],
    ),
    SmokeTestScript(
        "Thai", [("à¸à¸°à¹€à¸•à¸²à¹à¸”à¹‡à¸£", True), ("Ú˜×œØ±Ù†Ø§Ù„", False), ("wikipron", False)]
    ),
    SmokeTestScript(
        "Greek", [("Î²", True), ("Ú˜×œØ±Ù†Ø§Ù„", False), ("wikipron", False)]
    ),
    SmokeTestScript(
        "New Tai Lue",
        [("á¦ºá¦˜á§ˆá¦µá¦™á¦²á§‚", True), ("Ú˜×œØ±Ù†Ø§Ù„", False), ("wikipron", False)],
    ),
    SmokeTestScript(
        "Canadian Aboriginal",
        [("áŠá”¨á“ˆá“€á¤", True), ("Ú˜×œØ±Ù†Ø§Ù„", False), ("wikipron", False)],
    ),
    SmokeTestScript(
        "Myanmar",
        [("á€á€„á€ºá‚‡á€„á€°á€„á€ºá€¸", True), ("Ú˜×œØ±Ù†Ø§Ù„", False), ("wikipron", False)],
    ),
    SmokeTestScript(
        "Hangul", [("á„€á†á†¨ë‹¤ê¸°", True), ("Ú˜×œØ±Ù†Ø§Ù„", False), ("wikipron", False)]
    ),
    SmokeTestScript(
        "Tibetan",
        [("à½€à¼‹à½à¼‹à½˜à½“à¼‹à½à½´", True), ("Ú˜×œØ±Ù†Ø§Ù„", False), ("wikipron", False)],
    ),
    SmokeTestScript(
        "Syloti Nagri",
        [("ê €ê ê ê ‡ê £ê ê Ÿ", True), ("Ú˜×œØ±Ù†Ø§Ù„", False), ("wikipron", False)],
    ),
    SmokeTestScript(
        "Mongolian", [("á  á ¨á¡¨á  á¡¥á  ", True), ("Ú˜×œØ±Ù†Ø§Ù„", False), ("wikipron", False)]
    ),
    SmokeTestScript(
        "Khmer", [("á€á„áŸ‹á áŸ’á‚á¼ášá¼", True), ("Ú˜×œØ±Ù†Ø§Ù„", False), ("wikipron", False)]
    ),
    SmokeTestScript(
        "Javanese",
        [("ê¦§ê¦²ê¦¸ê¦±ê¦±ê§€ê¦ ê¦¿", True), ("Ú˜×œØ±Ù†Ø§Ù„", False), ("wikipron", False)],
    ),
    SmokeTestScript(
        "Common", [("Ê»", True), ("Ú˜×œØ±Ù†Ø§Ù„", False), ("wikipron", False)]
    ),
    SmokeTestScript(
        "Coptic", [("Ï£â²™â²â²›", True), ("Ú˜×œØ±Ù†Ø§Ù„", False), ("wikipron", False)]
    ),
    SmokeTestScript(
        "Ahom", [("ğ‘œ€ğ‘œ¦ğ‘œ¡ğ‘œ€ğ‘œ¨ğ‘œˆğ‘œ«ğ‘œ", True), ("Ú˜×œØ±Ù†Ø§Ù„", False), ("wikipron", False)]
    ),
    SmokeTestScript(
        "Armenian",
        [("Ö†Ö€Õ«Õ¸Ö‚Õ¬Õ¥Ö€Õ¥Õ¶", True), ("Ú˜×œØ±Ù†Ø§Ù„", False), ("wikipron", False)],
    ),
    SmokeTestScript(
        "Limbu",
        [("á¤€á¤ á¤€á¤¡á¤´á¤‹á¤ á¤´á¤á¤¡á¤°", True), ("Ú˜×œØ±Ù†Ø§Ù„", False), ("wikipron", False)],
    ),
    SmokeTestScript(
        "Bopomofo", [("ã„…ã„†ã„‡ã„ˆ", True), ("Ú˜×œØ±Ù†Ø§Ù„", False), ("wikipron", False)]
    ),
    SmokeTestScript(
        "Georgian",
        [("áƒáƒáƒ‘áƒáƒ áƒ’áƒ”áƒ‘áƒ¡", True), ("Ú˜×œØ±Ù†Ø§Ù„", False), ("wikipron", False)],
    ),
]


def _collect_scripts() -> Set[str]:
    scripts = set()
    with open(_LANGUAGES, "r") as source:
        languages = json.load(source)
    for lang in languages:
        if "script" in languages[lang]:
            for unicode_script in languages[lang]["script"].values():
                scripts.add(unicode_script)
    return scripts


@pytest.mark.parametrize(
    "observed_scripts, known_scripts",
    [(_collect_scripts(), [lang.script for lang in _SMOKE_TEST_LANGUAGES])],
)
def test_script_coverage(observed_scripts, known_scripts):
    """All scripts added to languages.json must be
    included in the smoke test.
    """
    for script in observed_scripts:
        assert (
            script in known_scripts
        ), f"{script} must be included in the smoke test."


@pytest.mark.parametrize("smoke_test_script,", _SMOKE_TEST_LANGUAGES)
def test_smoke_test_script(smoke_test_script):
    """Checks whether the scripts we'd like to split are appropriately handled
    by the Unicode script property."""
    for script_sample, predicted_truth_val in smoke_test_script.samples:
        assert (
            _generalized_check(smoke_test_script.script, script_sample, "")
            == predicted_truth_val
        )


@pytest.mark.parametrize("smoke_test_script,", _SMOKE_TEST_LANGUAGES)
def test_script_detection_strict(smoke_test_script):
    """Checks whether the scripts we'd like to split are correctly detected
    given the samples."""
    for script_sample, predicted_truth_val in smoke_test_script.samples:
        result = _detect_best_script_name(script_sample)
        predicted_script = result.replace("_", " ") if result else None
        status = predicted_script == smoke_test_script.script
        assert status == predicted_truth_val, (
            f"{script_sample}: {smoke_test_script.script} predicted"
            f" as {predicted_script}."
        )


def test_script_detection_basic():
    # Check mixing the scripts: Kharoá¹£á¹­hÄ« and BrÄhmÄ«, with a longer segment
    # corresponding to BrÄhmÄ«.
    text = "ğ¨‘ğ¨ªğ¨†ğ¨¯ğ¨ ğ¨ğ‘€˜ğ‘€ ğ‘€¬ğ‘„ğ‘€°ğ‘€ºğ‘€£ğ‘„"
    assert not _detect_best_script_name(text)  # Not allowed in strict mode.
    script = _detect_best_script_name(text, strict=False)
    assert script == "Brahmi"
